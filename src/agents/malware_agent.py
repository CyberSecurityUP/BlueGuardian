"""Malware analysis agent for Windows PE and Linux ELF files.

This agent specializes in static malware analysis, combining tool-based analysis
with AI-powered interpretation and threat intelligence.
"""

import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from src.agents.base_agent import (
    AnalysisResult,
    AnalysisStatus,
    BaseAgent,
    IOC,
    Verdict,
)
from src.ai_providers.base import BaseAIProvider
from src.ai_providers.consensus import ConsensusEngine
from src.analyzers.pe_analyzer import PEAnalyzer, PEAnalysisResult
from src.config.settings import Settings
from src.core.hallucination_guard import HallucinationGuard
from src.integrations.virustotal import VirusTotalClient
from src.prompts.malware_prompts import (
    MALWARE_ANALYSIS_SYSTEM_PROMPT,
    MALWARE_PE_ANALYSIS_PROMPT,
    format_prompt,
)


class MalwareAgent(BaseAgent):
    """Agent specialized in malware analysis.

    This agent performs comprehensive static analysis of potentially malicious files,
    focusing on Windows PE executables and Linux ELF binaries.
    """

    def __init__(
        self,
        settings: Settings,
        ai_providers: List[BaseAIProvider],
        consensus_engine: Optional[ConsensusEngine] = None,
        vt_client: Optional[VirusTotalClient] = None,
        hallucination_guard: Optional[HallucinationGuard] = None,
    ):
        """Initialize malware agent.

        Args:
            settings: Application settings
            ai_providers: AI providers for analysis
            consensus_engine: Multi-model consensus engine
            vt_client: VirusTotal client for threat intel
            hallucination_guard: Hallucination detection system
        """
        super().__init__(settings, ai_providers, consensus_engine)

        self.vt_client = vt_client
        self.hallucination_guard = hallucination_guard or HallucinationGuard(
            min_confidence_threshold=settings.hallucination_guard.min_confidence_score
        )
        self.pe_analyzer = PEAnalyzer()

        logger.info("Initialized MalwareAgent")

    def get_supported_file_types(self) -> List[str]:
        """Get supported file extensions.

        Returns:
            List of supported extensions
        """
        return ['.exe', '.dll', '.sys', '.bin', '.elf']

    def get_system_prompt(self) -> str:
        """Get malware analysis system prompt.

        Returns:
            System prompt
        """
        return MALWARE_ANALYSIS_SYSTEM_PROMPT

    async def analyze(self, artifact_path: str, **kwargs: Any) -> AnalysisResult:
        """Analyze a potentially malicious file.

        Args:
            artifact_path: Path to file to analyze
            **kwargs: Additional parameters (e.g., skip_vt, quick_triage)

        Returns:
            AnalysisResult with comprehensive findings

        Raises:
            ValueError: If file is invalid or unsupported
        """
        start_time = time.time()

        # Validate artifact
        self.validate_artifact(artifact_path)

        # Create result template
        result = self.create_result_template(artifact_path)
        result.status = AnalysisStatus.RUNNING

        logger.info(f"Starting malware analysis: {artifact_path}")

        try:
            # Step 1: Calculate file hashes
            logger.debug("Calculating file hashes")
            hashes = self.calculate_file_hash(artifact_path)
            result.details['hashes'] = hashes

            # Step 2: Query VirusTotal (if available and not skipped)
            vt_report = None
            vt_context = ""

            if self.vt_client and not kwargs.get('skip_vt', False):
                logger.debug("Querying VirusTotal")
                try:
                    vt_report = await self.vt_client.get_file_report(hashes['sha256'])
                    if vt_report:
                        vt_context = self.vt_client.format_report_for_ai(vt_report)
                        result.details['virustotal'] = {
                            'detections': f"{vt_report.malicious}/{vt_report.total_engines}",
                            'ratio': vt_report.detection_ratio(),
                            'threat_label': vt_report.popular_threat_label,
                        }
                except Exception as e:
                    logger.warning(f"VirusTotal query failed: {e}")
                    result.warnings.append(f"VirusTotal unavailable: {str(e)}")

            # Step 3: Perform static analysis based on file type
            path = Path(artifact_path)

            if path.suffix.lower() in ['.exe', '.dll', '.sys']:
                # Windows PE analysis
                pe_result = await self._analyze_pe(artifact_path, hashes, vt_context)
                result.tool_outputs = pe_result
                ai_response = pe_result.get('ai_response')

            elif path.suffix.lower() in ['.elf', '.bin']:
                # Linux ELF analysis (placeholder for now)
                logger.warning("ELF analysis not yet fully implemented")
                result.warnings.append("ELF analysis is limited in this version")
                ai_response = None

            else:
                raise ValueError(f"Unsupported file type: {path.suffix}")

            # Step 4: Validate AI response against tool outputs
            if ai_response and self.hallucination_guard:
                logger.debug("Validating AI response for hallucinations")
                validation = self.hallucination_guard.validate(
                    consensus_result=ai_response,
                    tool_outputs=result.tool_outputs,
                    expected_evidence_types=['hashes', 'sections', 'imports'],
                )

                result.confidence = validation.confidence
                result.warnings.extend(validation.warnings)

                if validation.contradictions:
                    result.errors.extend([
                        f"AI contradiction: {c['claim']}" for c in validation.contradictions
                    ])

            else:
                # No validation available
                result.confidence = ai_response.confidence_score if ai_response else 0.5

            # Step 5: Extract final verdict and IOCs
            if ai_response:
                result.summary = ai_response.merged_response
                result.ai_responses = ai_response

                # Extract verdict from AI response
                result.verdict = self._extract_verdict(ai_response.merged_response)

                # Extract IOCs from AI response and tool outputs
                result.iocs = self._extract_all_iocs(
                    ai_response.merged_response,
                    result.tool_outputs
                )

                # Extract MITRE techniques
                result.mitre_techniques = self._extract_mitre_techniques(
                    ai_response.merged_response
                )

                # Extract tags
                result.tags = self._extract_tags(ai_response.merged_response)

            # Set completion time
            result.completed_at = datetime.now()
            result.duration_seconds = time.time() - start_time
            result.status = AnalysisStatus.COMPLETED

            logger.info(
                f"Malware analysis complete: {result.verdict.value} "
                f"(confidence: {result.confidence:.0%}, "
                f"duration: {result.duration_seconds:.1f}s)"
            )

            return result

        except Exception as e:
            logger.error(f"Malware analysis failed: {e}", exc_info=True)
            result.status = AnalysisStatus.FAILED
            result.errors.append(str(e))
            result.completed_at = datetime.now()
            result.duration_seconds = time.time() - start_time
            raise

    async def _analyze_pe(
        self, file_path: str, hashes: Dict[str, str], vt_context: str
    ) -> Dict[str, Any]:
        """Analyze a Windows PE file.

        Args:
            file_path: Path to PE file
            hashes: File hashes
            vt_context: VirusTotal context string

        Returns:
            Dictionary with PE analysis results and AI response
        """
        logger.debug("Performing PE analysis")

        # Run PE analyzer
        pe_result: PEAnalysisResult = self.pe_analyzer.analyze(file_path)

        # Format data for AI
        context = self._format_pe_context(pe_result, hashes, vt_context)

        # Query AI with PE analysis data
        prompt = format_prompt(
            MALWARE_PE_ANALYSIS_PROMPT,
            **context
        )

        ai_response = await self.query_ai(
            user_message=prompt,
            temperature=0.0,  # Deterministic for analysis
        )

        # Package results
        return {
            'pe_analysis': {
                'architecture': pe_result.architecture,
                'subsystem': pe_result.subsystem,
                'is_packed': pe_result.is_packed,
                'packer': pe_result.packer_name,
                'section_count': pe_result.section_count,
                'imports_count': pe_result.imports_count,
                'suspicious_imports': pe_result.suspicious_imports,
                'suspicious_sections': pe_result.suspicious_sections,
                'suspicious_strings': pe_result.suspicious_strings,
                'anomalies': pe_result.anomalies,
            },
            'hashes': hashes,
            'sections': [
                {
                    'name': s.name,
                    'entropy': s.entropy,
                    'suspicious': s.suspicious,
                    'reasons': s.reasons,
                }
                for s in pe_result.sections
            ],
            'imports': [
                {
                    'dll': imp.dll,
                    'function': imp.function,
                    'suspicious': imp.suspicious,
                    'category': imp.category,
                }
                for imp in pe_result.imports[:100]  # Limit for context
            ],
            'ai_response': ai_response,
        }

    def _format_pe_context(
        self, pe_result: PEAnalysisResult, hashes: Dict[str, str], vt_context: str
    ) -> Dict[str, str]:
        """Format PE analysis data for AI prompt.

        Args:
            pe_result: PE analysis result
            hashes: File hashes
            vt_context: VirusTotal context

        Returns:
            Dictionary of formatted context sections
        """
        file_info = f"""
File: {pe_result.file_path}
Size: {pe_result.file_size} bytes
MD5: {hashes['md5']}
SHA1: {hashes['sha1']}
SHA256: {hashes['sha256']}
"""

        pe_headers = f"""
Architecture: {pe_result.architecture}
Subsystem: {pe_result.subsystem}
Compilation: {pe_result.compilation_timestamp or 'Unknown'}
Packed: {pe_result.is_packed} ({pe_result.packer_name or 'N/A'})
"""

        sections = "\n".join([
            f"- {s.name}: entropy={s.entropy:.2f}, size={s.virtual_size}, "
            f"flags={','.join(s.characteristics)}"
            + (f" [SUSPICIOUS: {', '.join(s.reasons)}]" if s.suspicious else "")
            for s in pe_result.sections
        ])

        imports = "\n".join([
            f"- {imp.dll}!{imp.function}"
            + (f" [{imp.category}]" if imp.suspicious else "")
            for imp in pe_result.imports[:50]
        ])

        exports = "\n".join([
            f"- {exp.name} (ord {exp.ordinal})"
            for exp in pe_result.exports[:20]
        ]) if pe_result.exports else "None"

        strings = "\n".join([
            f"- {s[:100]}"
            for s in pe_result.suspicious_strings[:30]
        ]) if pe_result.suspicious_strings else "None found"

        entropy = f"Average section entropy: {sum(s.entropy for s in pe_result.sections) / len(pe_result.sections):.2f}" if pe_result.sections else "N/A"

        if pe_result.anomalies:
            entropy += "\nAnomalies: " + ", ".join(pe_result.anomalies)

        return {
            'file_info': file_info.strip(),
            'pe_headers': pe_headers.strip(),
            'sections': sections or "No sections",
            'imports': imports or "No imports",
            'exports': exports,
            'strings': strings,
            'entropy': entropy,
            'virustotal_data': vt_context or "VirusTotal: Not queried",
        }

    def _extract_verdict(self, ai_response: str) -> Verdict:
        """Extract verdict from AI response.

        Args:
            ai_response: AI response text

        Returns:
            Verdict enum
        """
        response_lower = ai_response.lower()

        if 'malicious' in response_lower:
            return Verdict.MALICIOUS
        elif 'suspicious' in response_lower:
            return Verdict.SUSPICIOUS
        elif 'clean' in response_lower or 'benign' in response_lower:
            return Verdict.CLEAN
        else:
            return Verdict.UNKNOWN

    def _extract_all_iocs(self, ai_response: str, tool_outputs: Dict[str, Any]) -> List[IOC]:
        """Extract IOCs from AI response and tool outputs.

        Args:
            ai_response: AI response text
            tool_outputs: Tool outputs

        Returns:
            List of IOCs
        """
        iocs = []

        # Extract from AI response
        ai_iocs = self.extract_iocs_from_text(ai_response)
        iocs.extend(ai_iocs)

        # Extract from tool outputs (suspicious strings)
        if 'pe_analysis' in tool_outputs:
            pe_data = tool_outputs['pe_analysis']

            for string in pe_data.get('suspicious_strings', []):
                string_iocs = self.extract_iocs_from_text(string)
                iocs.extend(string_iocs)

        # Remove duplicates
        unique_iocs = []
        seen = set()

        for ioc in iocs:
            key = (ioc.type, ioc.value)
            if key not in seen:
                seen.add(key)
                unique_iocs.append(ioc)

        return unique_iocs

    def _extract_mitre_techniques(self, ai_response: str) -> List[str]:
        """Extract MITRE ATT&CK technique IDs from AI response.

        Args:
            ai_response: AI response text

        Returns:
            List of technique IDs (e.g., ['T1055', 'T1082'])
        """
        import re

        # Extract T#### patterns
        pattern = r'\bT\d{4}(?:\.\d{3})?\b'
        techniques = re.findall(pattern, ai_response)

        return list(set(techniques))  # Remove duplicates

    def _extract_tags(self, ai_response: str) -> List[str]:
        """Extract relevant tags from AI response.

        Args:
            ai_response: AI response text

        Returns:
            List of tags
        """
        tags = []
        response_lower = ai_response.lower()

        # Common malware categories
        categories = [
            'trojan', 'ransomware', 'backdoor', 'keylogger', 'stealer',
            'downloader', 'dropper', 'loader', 'cryptominer', 'worm',
            'rootkit', 'rat', 'bot', 'spyware', 'adware'
        ]

        for category in categories:
            if category in response_lower:
                tags.append(category)

        # Techniques
        techniques = [
            'process_injection', 'code_injection', 'persistence',
            'privilege_escalation', 'defense_evasion', 'credential_dumping',
            'lateral_movement', 'exfiltration', 'c2', 'anti_analysis'
        ]

        for technique in techniques:
            if technique.replace('_', ' ') in response_lower:
                tags.append(technique)

        return list(set(tags))
